{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$: cantidad de neuronas  \n",
    "$L$: cantidad de capas  \n",
    "$lr$: learning rate  \n",
    "$g(z)$: función de activación  \n",
    "$\\frac{dg}{dz}(z)$: derivada de la función de activación  \n",
    "$C(\\bm{X},\\bm{Y},\\bm{W},\\bm{B})$: función de costo/pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "C\n",
    "&=\n",
    "% suma de las diferencias de las N activaciones de la última (L) capa con los N elementos de y al cuadrado\n",
    "\\sum_{i=1}^N \n",
    "\\left( \n",
    "    a_{L}^{(i)} - y^{(i)}\n",
    "\\right)^2\n",
    "\\\\\n",
    "% expansión de la suma\n",
    "&=\n",
    "\\left(\n",
    "    a_{L}^{(1)} - y^{(1)}\n",
    "\\right)^2\n",
    "+ \\dots +\n",
    "\\left(\n",
    "    a_{L}^{(N)} - y^{(N)}\n",
    "\\right)^2\n",
    "\\\\\n",
    "% expansión de las activaciones en sigma(z)\n",
    "&=\n",
    "\\left(\n",
    "\\sigma(z_{L}^{(1)}) - y^{(1)}\n",
    "\\right)^2\n",
    "+ \\dots +\n",
    "\\left(\n",
    "\\sigma(z_{L}^{(N)}) - y^{(N)}\n",
    "\\right)^2\n",
    "\\\\\n",
    "% expansión de los z\n",
    "&=\n",
    "\\left(\n",
    "\\sigma\\left(w_L^{(1)} \\left( \\frac{1}{M} \\sum_{j=1}^M a_{L-1}^{(j)} \\right) + b_L^{(1)} \\right) - y^{(1)}\n",
    "\\right)^2\n",
    "+ \\dots +\n",
    "\\left(\n",
    "\\sigma\\left(w_L^{(N)} \\left( \\frac{1}{M} \\sum_{j=1}^M a_{L-1}^{(j)} \\right) + b_L^{(N)} \\right) - y^{(N)}\n",
    "\\right)^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bm{W}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\bm{w}_{(1)}^{(1)} & \\bm{w}_{(2)}^{(1)} & \\dots & \\bm{w}_{(L)}^{(1)}\\\\\n",
    "\\bm{w}_{(1)}^{(2)} & \\bm{w}_{(2)}^{(2)} & \\dots & \\bm{w}_{(L)}^{(2)}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\bm{w}_{(1)}^{(N)} & \\bm{w}_{(2)}^{(N)} & \\dots & \\bm{w}_{(L)}^{(N)}\\\\\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "% \\begin{aligned}\n",
    "\\bm{w}_{(l)}^{(n)}\n",
    "% &=\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\text{peso de } a_{(l-1)}^{(1)} \\rightarrow a_{(l)}^{(n)}\\\\\n",
    "\\text{peso de } a_{(l-1)}^{(2)} \\rightarrow a_{(l)}^{(n)}\\\\\n",
    "\\vdots\\\\\n",
    "\\text{peso de } a_{(l-1)}^{(M)} \\rightarrow a_{(l)}^{(n)}\\\\\n",
    "\\end{bmatrix}\n",
    "% &=\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "w_{(l)}^{(n,1)}\\\\\n",
    "w_{(l)}^{(n,2)}\\\\\n",
    "\\vdots\\\\\n",
    "w_{(l)}^{(n,M)}\n",
    "\\end{bmatrix}\n",
    "% \\end{aligned}\n",
    "$$\n",
    "con $M$ la cantidad de nueronas de la capa anterior.  \n",
    "Abusando notación:\n",
    "$$\n",
    "\\bm{W}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "w_{(1)}^{(1,1)}\\\\\n",
    "\\vdots\\\\\n",
    "w_{(1)}^{(1,M)}\n",
    "\\end{bmatrix}\n",
    "& \\dots &\n",
    "\\begin{bmatrix}\n",
    "w_{(L)}^{(1,1)}\\\\\n",
    "\\vdots\\\\\n",
    "w_{(L)}^{(1,M)}\n",
    "\\end{bmatrix}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\begin{bmatrix}\n",
    "w_{(1)}^{(N,1)}\\\\\n",
    "\\vdots\\\\\n",
    "w_{(1)}^{(N,M)}\n",
    "\\end{bmatrix}\n",
    "& \\dots &\n",
    "\\begin{bmatrix}\n",
    "w_{(L)}^{(N,1)}\\\\\n",
    "\\vdots\\\\\n",
    "w_{(L)}^{(N,M)}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def mse(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred)**2)\n",
    "\n",
    "class Net():\n",
    "# feedforward network: las activaciones van hacia adelante\n",
    "    def __init__(self, N, L=1, lr=0.01, g=sigmoid, d_g=d_sigmoid, C=mse):\n",
    "# N: cantidad de neuronas por capa, L: cantidad de capas y lr: learning rate\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.A = np.zeros([N,L])\n",
    "        self.W = np.zeros((N,L,N))\n",
    "        self.B = np.zeros((N,L,N))\n",
    "# W y B son matrices \"tridimensionales\", un elemento de la primera matriz indica al peso de qué activación nos estamos refiriendo en la capa actual, recorrer la lista asociada a ese elemento nos devuelve los N (por ahora N porque la matriz la estoy implementando rectangular) pesos asociados a esa activación de la capa anterior, o sea w[L,n][L-1,n for n in N de la capa anterior]\n",
    "        self.lr = lr\n",
    "        self.g = g\n",
    "        self.d_g = d_g\n",
    "        self.C = C\n",
    "# W: matriz de pesos, A: matriz de activaciones y B: matriz de sesgos\n",
    "# g es la función de activación y d_g es su derivada, C es la función de costo\n",
    "\n",
    "    def learn(self, X, Y, tol=0.1): # la tolerancia está alta para probar rápido :)\n",
    "        self.W = np.random.rand(self.N,self.L,self.N)\n",
    "        self.B = np.random.rand(self.N,self.L,self.N)\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    np.mean(\n",
    "                        self.g(self.W[n][l][m] * self.X[m] + self.B[n][l][m])\n",
    "                        if l == 0\n",
    "                        else\n",
    "                        self.g(self.W[n][l][m] * self.A[m][l] + self.B[n][l][m])\n",
    "                        for m in range(self.N)\n",
    "                    )\n",
    "                    for n in range(self.N)\n",
    "                ]\n",
    "                for l in range(self.L)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        while C(Y, self.predict(X)) > tol:\n",
    "# calculo el gradiente de C con respecto a W y B, son matrices de N*L*N\n",
    "            grad_C_W = np.array(\n",
    "                            [\n",
    "                                [\n",
    "                                    [\n",
    "\n",
    "                                    ]\n",
    "                                ]\n",
    "                            ]\n",
    "                       )\n",
    "            grad_C_B = np.array(\n",
    "                            [\n",
    "                                [\n",
    "                                    [\n",
    "\n",
    "                                    ]\n",
    "                                ]\n",
    "                            ]\n",
    "                       )\n",
    "\n",
    "# muevo W y B en la dirección contraria al gradiente con módulo lr\n",
    "            for l in range(L):\n",
    "                for n in range(N):\n",
    "                    for m in range(N):\n",
    "                        W[n][l][m] -= lr * grad_C_W[n][l][m]\n",
    "                        B[n][l][m] -= lr * grad_C_B[n][l][m]\n",
    "\n",
    "            # W -= lr * grad_C_W\n",
    "            # B -= lr * grad_C_B ????????\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.g(self.W[n][l] * X[n] + self.B[n][l]) # la primer capa tiene como inputs los elementos de X\n",
    "                    if l == 0 \n",
    "                    else\n",
    "                    self.g(self.W[n][l] * self.A[n][l-1] + self.B[n][l])\n",
    "\n",
    "                    for l in range(self.L)\n",
    "                ]\n",
    "                for n in range(self.N)\n",
    "            ]\n",
    "        )\n",
    "        return self.A[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "I,J,K = 3,3,3\n",
    "# A = np.array(\n",
    "#         [\n",
    "#             [\n",
    "#                 [\n",
    "#                     str(i)+\",\"+str(j)+\",\"+str(k)\n",
    "#                     for k in range(K)\n",
    "#                 ]\n",
    "#             for j in range(J)\n",
    "#             ]\n",
    "#         for i in range(I)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "np.random.rand(I,J,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/red.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red de arriba, tenemos:\n",
    "La matriz de activaciones $A$ es:\n",
    "$$\n",
    "A\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{(1)}^{(1)}   &   y^{(1)}\\\\\n",
    "a_{(2)}^{(1)}   &   y^{(1)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "La matriz de pesos $W$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\bm{w}_{(1)}^{(1)}    &   \\bm{w}_{(2)}^{(1)}\\\\\n",
    "\\bm{w}_{(1)}^{(2)}    &   \\bm{w}_{(2)}^{(2)}\\\\\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_{(1)}^{(1,1)}\\\\\n",
    "w_{(1)}^{(1,2)}\n",
    "\\end{bmatrix}    &   \\begin{bmatrix}\n",
    "                     w_{(2)}^{(1,1)}\\\\\n",
    "                     w_{(2)}^{(1,2)}\n",
    "                     \\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "w_{(1)}^{(2,1)}\\\\\n",
    "w_{(1)}^{(2,2)}\n",
    "\\end{bmatrix}    &   \\begin{bmatrix}\n",
    "                     w_{(2)}^{(2,1)}\\\\\n",
    "                     w_{(2)}^{(2,2)}\n",
    "                     \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "El gradiente de $C$ con respecto de $\\bm{W}$, $\\nabla C_{\\bm{W}}$\n",
    "$$\n",
    "\\nabla C_{\\bm{W}}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\partial C / \\partial w_{(1)}^{(1,1)}\\\\\n",
    "\\partial C / \\partial w_{(1)}^{(1,2)}\n",
    "\\end{bmatrix}    &   \\begin{bmatrix}\n",
    "                     \\partial C / \\partial w_{(2)}^{(1,1)}\\\\\n",
    "                     \\partial C / \\partial w_{(2)}^{(1,2)}\n",
    "                     \\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "\\partial C / \\partial w_{(1)}^{(2,1)}\\\\\n",
    "\\partial C / \\partial w_{(1)}^{(2,2)}\n",
    "\\end{bmatrix}    &   \\begin{bmatrix}\n",
    "                     \\partial C / \\partial w_{(2)}^{(2,1)}\\\\\n",
    "                     \\partial C / \\partial w_{(2)}^{(2,2)}\n",
    "                     \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para un patrón, el error $C_0$ es:\n",
    "$$\n",
    "C_0\n",
    "=\n",
    "\\left(\n",
    "    y^{(1)} - \\hat y^{(1)}\n",
    "\\right)^2\n",
    "+\n",
    "\\left(\n",
    "    y^{(2)} - \\hat y^{(2)}\n",
    "\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las derivadas parciales con respecto de los pesos son:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w_{(1)}^{(1,1)}}\n",
    "&= \n",
    "\n",
    "\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(1)}^{(1,2)}}\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(2)}^{(1,1)}}\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(2)}^{(1,2)}}\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(1)}^{(2,1)}}\n",
    "&=\n",
    "&\\frac{\\partial C}{\\partial y^{(2)}}&\n",
    "&\\frac{\\partial y^{(2)}}{\\partial z_{(2)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(2)}^{(2)}}{\\partial a_{(1)}^{(2)}}&\n",
    "&\\frac{\\partial a_{(1)}^{(2)}}{\\partial z_{(1)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(1)}^{(2)}}{\\partial w_{(1)}^{(2,1)}}&\\\\\n",
    "&=\n",
    "&2(y^{(2)} - \\hat y^{(2)})&\n",
    "&\\sigma'(z_{(2)}^{(2)})&\n",
    "&w_{(2)}^{(2)}&\n",
    "&\\sigma'(z_{(1)}^{(2)})&\n",
    "&x^{(1)}&\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(1)}^{(2,2)}}\n",
    "&=\n",
    "&\\frac{\\partial C}{\\partial y^{(2)}}&\n",
    "&\\frac{\\partial y^{(2)}}{\\partial z_{(2)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(2)}^{(2)}}{\\partial a_{(1)}^{(2)}}&\n",
    "&\\frac{\\partial a_{(1)}^{(2)}}{\\partial z_{(1)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(1)}^{(2)}}{\\partial w_{(1)}^{(2,2)}}&\\\\\n",
    "&=\n",
    "&2(y^{(2)} - \\hat y^{(2)})&\n",
    "&\\sigma'(z_{(2)}^{(2)})&\n",
    "&w_{(2)}^{(2)}&\n",
    "&\\sigma'(z_{(1)}^{(2)})&\n",
    "&x^{(2)}&\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(2)}^{(2,1)}}\n",
    "&=\n",
    "&\\frac{\\partial C}{\\partial y^{(2)}}&\n",
    "&\\frac{\\partial y^{(2)}}{\\partial z_{(2)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(2)}^{(2)}}{\\partial w_{(2)}^{(2,1)}}&\\\\\n",
    "&=\n",
    "&2(y^{(2)} - \\hat y^{(2)})&\n",
    "&\\sigma'(z_{(2)}^{(2)})&\n",
    "&a_{(1)}^{(1)}&\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{\\partial C}{\\partial w_{(2)}^{(2,2)}}\n",
    "&=\n",
    "&\\frac{\\partial C}{\\partial y_{(2)}}&\n",
    "&\\frac{\\partial y^{(2)}}{\\partial z_{(2)}^{(2)}}&\n",
    "&\\frac{\\partial z_{(2)}^{(2)}}{\\partial w_{(2)}^{(2,2)}}&\\\\\n",
    "&=\n",
    "&2(y^{(2)} - \\hat y^{(2)})&\n",
    "&\\sigma'(z_{(2)}^{(2)})&\n",
    "&a_{(1)}^{(2)}&\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/red.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
