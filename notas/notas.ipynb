{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10315979117250132)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "class Net():\n",
    "    def __init__(self):\n",
    "        self.w1 = random.random()\n",
    "        self.w2 = random.random()\n",
    "        self.lr = 0.1\n",
    "    def learn(self, x, y):\n",
    "        z1 = self.w1 * x\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = self.w2 * a1\n",
    "        a2 = sigmoid(z2)\n",
    "        c = (a2 - y)**2\n",
    "        tol_c = 0.00001\n",
    "        while c > tol_c:\n",
    "            # calcular el gradiente de c(w1, w2)\n",
    "            d_z1_w1 = x\n",
    "            d_a1_z1 = d_sigmoid(z1)\n",
    "            d_z2_a1 = self.w2\n",
    "            d_c_a2 = 2 * (a2 - y)\n",
    "            d_z2_w2 = a1\n",
    "            d_a2_z2 = d_sigmoid(z2)\n",
    "\n",
    "            d_c_w1 = d_c_a2 * d_a2_z2 * d_z2_a1 * d_a1_z1 * d_z1_w1\n",
    "            d_c_w2 = d_c_a2 * d_a2_z2 * d_z2_w2\n",
    "\n",
    "            # gr_c = [d_c_w1, d_c_w2]\n",
    "            # mover w1 y w2 en dirección contraria al gradiente\n",
    "            self.w1 -= self.lr * d_c_w1\n",
    "            self.w2 -= self.lr * d_c_w2\n",
    "\n",
    "\n",
    "            # actualizo lo de afuero del while \n",
    "            z1 = self.w1 * x\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = self.w2 * a1\n",
    "            a2 = sigmoid(z2)\n",
    "            c = (a2 - y)**2\n",
    "\n",
    "    def predict(self, x):\n",
    "        z1 = self.w1 * x\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = self.w2 * a1\n",
    "        a2 = sigmoid(z2)\n",
    "        z1 = self.w1 * x\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = self.w2 * a1\n",
    "        a2 = sigmoid(z2)\n",
    "        return a2\n",
    "\n",
    "net = Net()\n",
    "net.learn(1, 0.1)\n",
    "net.predict(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$: cantidad de neuronas  \n",
    "$L$: cantidad de capas  \n",
    "$lr$: learning rate  \n",
    "$g(z)$: función de activación  \n",
    "$\\frac{dg}{dz}(z)$: derivada de la función de activación  \n",
    "$C(\\bm{X},\\bm{Y},\\bm{W},\\bm{B})$: función de costo/pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def mse(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred)**2)\n",
    "\n",
    "class Net():\n",
    "# feedforward network: las activaciones van hacia adelante\n",
    "    def __init__(self, N, L=1, lr=0.01, g=sigmoid, d_g=d_sigmoid, C=mse):\n",
    "# N: cantidad de neuronas por capa, L: cantidad de capas y lr: learning rate\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.A = np.zeros([N,L])\n",
    "        self.W = np.zeros([N,L])\n",
    "        self.B = np.zeros([N,L])\n",
    "        self.lr = lr\n",
    "        self.g = g\n",
    "        self.d_g = d_g\n",
    "        self.C = C\n",
    "# W: matriz de pesos, de N filas por L columnas, A: matriz de activaciones y B: matriz de sesgos\n",
    "# g es la función de activación y d_g es su derivada, C es la función de costo\n",
    "\n",
    "    def learn(self, X, Y, tol=0.1): # la tolerancia está alta para probar rápido :)\n",
    "        self.W = np.random.rand(self.N,self.L,self.N)\n",
    "        self.B = np.random.rand(self.N,self.L,self.N)\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.g(self.W[n][l] * X[n] + self.B[n][l]) # la primer capa tiene como inputs los elementos de X\n",
    "                    if l == 0 \n",
    "                    else\n",
    "                    self.g(self.W[n][l] * self.A[n][l-1] + self.B[n][l])\n",
    "\n",
    "                    for l in range(self.L)\n",
    "                ]\n",
    "                for n in range(self.N)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# te debo implementar las derivadas para mañana xddd\n",
    "# mentira, voy a intentar ahora!!!!!!\n",
    "\n",
    "        while C(Y, self.predict(X)) > tol:\n",
    "            # calculo el gradiente de C con respecto a W y B\n",
    "\n",
    "            # muevo W en la dirección contraria al gradiente con módulo lr\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        z1 = self.w1 * x\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = self.w2 * a1\n",
    "        a2 = sigmoid(z2)\n",
    "        c = (a2 - y)**2\n",
    "        tol_c = 0.00001\n",
    "        while c > tol_c:\n",
    "            # calcular el gradiente de c(w1, w2)\n",
    "            d_z1_w1 = x\n",
    "            d_a1_z1 = d_sigmoid(z1)\n",
    "            d_z2_a1 = self.w2\n",
    "            d_c_a2 = 2 * (a2 - y)\n",
    "            d_z2_w2 = a1\n",
    "            d_a2_z2 = d_sigmoid(z2)\n",
    "\n",
    "            d_c_w1 = d_c_a2 * d_a2_z2 * d_z2_a1 * d_a1_z1 * d_z1_w1\n",
    "            d_c_w2 = d_c_a2 * d_a2_z2 * d_z2_w2\n",
    "\n",
    "            # gr_c = [d_c_w1, d_c_w2]\n",
    "            # mover w1 y w2 en dirección contraria al gradiente\n",
    "            self.w1 -= self.lr * d_c_w1\n",
    "            self.w2 -= self.lr * d_c_w2\n",
    "\n",
    "\n",
    "            # actualizo lo de afuero del while \n",
    "            z1 = self.w1 * x\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = self.w2 * a1\n",
    "            a2 = sigmoid(z2)\n",
    "            c = (a2 - y)**2\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.g(self.W[n][l] * X[n] + self.B[n][l]) # la primer capa tiene como inputs los elementos de X\n",
    "                    if l == 0 \n",
    "                    else\n",
    "                    self.g(self.W[n][l] * self.A[n][l-1] + self.B[n][l])\n",
    "\n",
    "                    for l in range(self.L)\n",
    "                ]\n",
    "                for n in range(self.N)\n",
    "            ]\n",
    "        )\n",
    "        return self.A[:, -1]\n",
    "# actualizo la matriz A y retorno la última capa, no?\n",
    "        # z1 = self.w1 * x\n",
    "        # a1 = sigmoid(z1)\n",
    "        # z2 = self.w2 * a1\n",
    "        # a2 = sigmoid(z2)\n",
    "        # z1 = self.w1 * x\n",
    "        # a1 = sigmoid(z1)\n",
    "        # z2 = self.w2 * a1\n",
    "        # a2 = sigmoid(z2)\n",
    "        # return a2\n",
    "\n",
    "net = Net()\n",
    "net.learn(1, 0.1)\n",
    "net.predict(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'while' statement on line 83 (1487729148.py, line 91)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 91\u001b[0;36m\u001b[0m\n\u001b[0;31m    z1 = self.w1 * x\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'while' statement on line 83\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def mse(Y, Y_pred):\n",
    "    return np.mean((Y - Y_pred)**2)\n",
    "\n",
    "class Net():\n",
    "# feedforward network: las activaciones van hacia adelante\n",
    "    def __init__(self, N, L=1, lr=0.01, g=sigmoid, d_g=d_sigmoid, C=mse):\n",
    "# N: cantidad de neuronas por capa, L: cantidad de capas y lr: learning rate\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.A = np.zeros([N,L])\n",
    "        self.W = np.zeros((N,L,N))\n",
    "        self.B = np.zeros((N,L,N))\n",
    "# W y B son matrices \"tridimensionales\", un elemento de la primera matriz indica al peso de qué activación nos estamos refiriendo en la capa actual, recorrer la lista asociada a ese elemento nos devuelve los N (por ahora N porque la matriz la estoy implementando rectangular) pesos asociados a esa activación de la capa anterior, o sea w[L,n][L-1,n for n in N de la capa anterior]\n",
    "        self.lr = lr\n",
    "        self.g = g\n",
    "        self.d_g = d_g\n",
    "        self.C = C\n",
    "# W: matriz de pesos, A: matriz de activaciones y B: matriz de sesgos\n",
    "# g es la función de activación y d_g es su derivada, C es la función de costo\n",
    "\n",
    "    def learn(self, X, Y, tol=0.1): # la tolerancia está alta para probar rápido :)\n",
    "        self.W = np.random.rand(self.N,self.L,self.N)\n",
    "        self.B = np.random.rand(self.N,self.L,self.N)\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    np.mean(\n",
    "                        self.g(self.W[n][l][m] * self.X[m] + self.B[n][l][m])\n",
    "                        if l == 0\n",
    "                        else\n",
    "                        self.g(self.W[n][l][m] * self.A[m][l] + self.B[n][l][m])\n",
    "                        for m in range(N)\n",
    "                    )\n",
    "                    for n in range(N)\n",
    "                ]\n",
    "                for l in range(L)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        while C(Y, self.predict(X)) > tol:\n",
    "            # calculo el gradiente de C con respecto a W y B\n",
    "\n",
    "            # muevo W en la dirección contraria al gradiente con módulo lr\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        z1 = self.w1 * x\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = self.w2 * a1\n",
    "        a2 = sigmoid(z2)\n",
    "        c = (a2 - y)**2\n",
    "        tol_c = 0.00001\n",
    "        while c > tol_c:\n",
    "            # calcular el gradiente de c(w1, w2)\n",
    "            d_z1_w1 = x\n",
    "            d_a1_z1 = d_sigmoid(z1)\n",
    "            d_z2_a1 = self.w2\n",
    "            d_c_a2 = 2 * (a2 - y)\n",
    "            d_z2_w2 = a1\n",
    "            d_a2_z2 = d_sigmoid(z2)\n",
    "\n",
    "            d_c_w1 = d_c_a2 * d_a2_z2 * d_z2_a1 * d_a1_z1 * d_z1_w1\n",
    "            d_c_w2 = d_c_a2 * d_a2_z2 * d_z2_w2\n",
    "\n",
    "            # gr_c = [d_c_w1, d_c_w2]\n",
    "            # mover w1 y w2 en dirección contraria al gradiente\n",
    "            self.w1 -= self.lr * d_c_w1\n",
    "            self.w2 -= self.lr * d_c_w2\n",
    "\n",
    "\n",
    "            # actualizo lo de afuero del while \n",
    "            z1 = self.w1 * x\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = self.w2 * a1\n",
    "            a2 = sigmoid(z2)\n",
    "            c = (a2 - y)**2\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.A = np.array(\n",
    "            [\n",
    "                [\n",
    "                    self.g(self.W[n][l] * X[n] + self.B[n][l]) # la primer capa tiene como inputs los elementos de X\n",
    "                    if l == 0 \n",
    "                    else\n",
    "                    self.g(self.W[n][l] * self.A[n][l-1] + self.B[n][l])\n",
    "\n",
    "                    for l in range(self.L)\n",
    "                ]\n",
    "                for n in range(self.N)\n",
    "            ]\n",
    "        )\n",
    "        return self.A[:, -1]\n",
    "# actualizo la matriz A y retorno la última capa, no?\n",
    "        # z1 = self.w1 * x\n",
    "        # a1 = sigmoid(z1)\n",
    "        # z2 = self.w2 * a1\n",
    "        # a2 = sigmoid(z2)\n",
    "        # z1 = self.w1 * x\n",
    "        # a1 = sigmoid(z1)\n",
    "        # z2 = self.w2 * a1\n",
    "        # a2 = sigmoid(z2)\n",
    "        # return a2\n",
    "\n",
    "net = Net()\n",
    "net.learn(1, 0.1)\n",
    "net.predict(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.83060429, 0.22837331, 0.64303606],\n",
       "        [0.52401112, 0.41095453, 0.48532843],\n",
       "        [0.26870965, 0.72763997, 0.13208113]],\n",
       "\n",
       "       [[0.27600584, 0.62032311, 0.14461211],\n",
       "        [0.22155067, 0.56802093, 0.33854916],\n",
       "        [0.59478769, 0.27128924, 0.13405246]],\n",
       "\n",
       "       [[0.3890637 , 0.10842584, 0.62112779],\n",
       "        [0.994863  , 0.14124666, 0.6253422 ],\n",
       "        [0.03533958, 0.95520182, 0.90321558]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "I,J,K = 3,3,3\n",
    "# A = np.array(\n",
    "#         [\n",
    "#             [\n",
    "#                 [\n",
    "#                     str(i)+\",\"+str(j)+\",\"+str(k)\n",
    "#                     for k in range(K)\n",
    "#                 ]\n",
    "#             for j in range(J)\n",
    "#             ]\n",
    "#         for i in range(I)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "np.random.rand(I,J,K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
