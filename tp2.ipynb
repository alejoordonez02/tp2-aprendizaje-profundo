{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implemente un perceptrón simple que aprenda la función lógica $AND$ y la función lógica $OR$, de $2$ y de $4$ entradas. Muestre la evolución del error durante el entrenamiento. Para el caso de $2$ dimensiones, grafique la recta discriminadora y todos los vectores de entrada de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/perceptrón-simple1.png)\n",
    "\n",
    "$AND$ de $2$ entradas:\n",
    "| $x_1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $0$ | $0$ | $1$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(X):\n",
    "    return all(X)\n",
    "\n",
    "def OR(X):\n",
    "    return any(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSimple:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(3)\n",
    "    def train(self, X, Y, alpha, iter_):\n",
    "        for _ in range(iter_):\n",
    "            for n in range(len(X)):\n",
    "                a = self.predict(X[n])\n",
    "                if a != Y[n]:\n",
    "                    self.W[0] += alpha * (Y[n] - a) * X[n][0]\n",
    "                    self.W[1] += alpha * (Y[n] - a) * X[n][1]\n",
    "                    self.W[2] += alpha * (Y[n] - a) * (-1)\n",
    "    def predict(self, x):\n",
    "        h = np.dot(np.append(x, -1), self.W)\n",
    "        return 0 if h < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 0\n",
      "[1, 0] 0\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1,x2] for x1 in [0,1] for x2 in[0,1]]\n",
    "Y_train = [AND(x) for x in X_train]\n",
    "\n",
    "perceptron = PerceptronSimple()\n",
    "perceptron.train(X_train[1:] + [[1,1]], Y_train[1:] + [True], 0.01, 10000)\n",
    "\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$AND$ de $4$ entradas:\n",
    "\n",
    "| $x_1$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ |\n",
    "| $x_3$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $0$ | $1$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "| $x_4$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $1$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSimple:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(5)\n",
    "    def train(self, X, Y, alpha, iter_):\n",
    "        for _ in range(iter_):\n",
    "            for n in range(len(X)):\n",
    "                a = self.predict(X[n])\n",
    "                if a != Y[n]:\n",
    "                    self.W[0] += alpha * (Y[n] - a) * X[n][0]\n",
    "                    self.W[1] += alpha * (Y[n] - a) * X[n][1]\n",
    "                    self.W[2] += alpha * (Y[n] - a) * X[n][2]\n",
    "                    self.W[3] += alpha * (Y[n] - a) * X[n][3]\n",
    "                    self.W[4] += alpha * (Y[n] - a) * (-1)\n",
    "    def predict(self, x):\n",
    "        h = np.dot(np.append(x, -1), self.W)\n",
    "        return 0 if h < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0] 0\n",
      "[0, 0, 0, 1] 0\n",
      "[0, 0, 1, 0] 0\n",
      "[0, 0, 1, 1] 0\n",
      "[0, 1, 0, 0] 0\n",
      "[0, 1, 0, 1] 0\n",
      "[0, 1, 1, 0] 0\n",
      "[0, 1, 1, 1] 0\n",
      "[1, 0, 0, 0] 0\n",
      "[1, 0, 0, 1] 0\n",
      "[1, 0, 1, 0] 0\n",
      "[1, 0, 1, 1] 0\n",
      "[1, 1, 0, 0] 0\n",
      "[1, 1, 0, 1] 0\n",
      "[1, 1, 1, 0] 0\n",
      "[1, 1, 1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1,x2,x3,x4] for x1 in [0,1] for x2 in[0,1] for x3 in [0,1] for x4 in[0,1]]\n",
    "Y_train = [AND(x) for x in X_train]\n",
    "\n",
    "perceptron = PerceptronSimple()\n",
    "perceptron.train(X_train[5:] + [[1,1,1,1] for _ in range(5)], Y_train[5:] + [True for _ in range(5)], 0.001, 10000)\n",
    "\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implemente un perceptrón multicapa que aprenda la función lógica $XOR$ de $2$ y de $4$ entradas (utilizando el algoritmo Backpropagation y actualizando en batch). Muestre cómo evoluciona el error durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/perceptrón-multicapa1.png)\n",
    "\n",
    "$XOR$ de $2$ entradas:\n",
    "| $x_1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $1$ | $1$ | $0$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "class PerceptronMulticapa:\n",
    "    def __init__(self, sizes):\n",
    "        self.L = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.a = [[0 for _ in range(s)] for s in sizes]\n",
    "        self.z = [[0 for _ in range(s)] for s in sizes[1:]]\n",
    "        self.w = [np.random.randn(n,m) for n, m in zip(sizes[1:], sizes[:-1])]\n",
    "        self.b = [np.random.randn(s) for s in sizes[1:]]\n",
    "    def predict(self, x):\n",
    "        self.a[0] = x\n",
    "        for l in range(1, self.L):\n",
    "            self.z[l-1] = self.w[l-1] @ self.a[l-1] + self.b[l-1]\n",
    "            self.a[l] = sigmoid(self.z[l-1])\n",
    "        # return 1 if self.a[-1] > 0.5 else 0\n",
    "        return self.a[-1]\n",
    "    # def train(self, X, Y, iters=1000):\n",
    "    #     # una pasada\n",
    "    #     # para cada x en X con su correspondiente y deseado en Y\n",
    "    #     for x, y in zip(X, Y):\n",
    "    #         # predecir x\n",
    "    #         a_out = self.predict(x)\n",
    "    #         # calcular el error\n",
    "    #         grad_C_a = self.a[L] - y\n",
    "    #         delta_l = grad_C_a * d_sigmoid(self.z[L-1])\n",
    "    #         # calcular el gradiente de C con respecto a w y b\n",
    "    #         grad_C_w = [np.zeros(n,m) for n, m in zip(sizes[1:], sizes[:-1])]\n",
    "    #         for l in range(L,0,-1):\n",
    "    #             delta_l = ((w[l]).dot(delta_l)) * d_sigmoid(z[l])\n",
    "    #             d_C_w = a[l-1] @ delta_l\n",
    "    #             grad_C_w[l] = d_C_w\n",
    "    #         # mover los parámetros en la dirección contraria al gradiente\n",
    "    #         self.w -= grad_C_w\n",
    "\n",
    "    def train(self, X, Y, lr=0.01, iters=1000):\n",
    "        for _ in range(iters):  # Iterar varias veces\n",
    "            for x, y in zip(X, Y):\n",
    "                # predigo x para actualizar la matriz de activaciones\n",
    "                self.predict(x)\n",
    "                \n",
    "                # calculo el error\n",
    "                grad_C_a = self.a[-1] - y\n",
    "                delta_l = grad_C_a * d_sigmoid(self.z[-1])\n",
    "                \n",
    "                # inicializo los gradientes\n",
    "                grad_C_w = [np.zeros_like(w) for w in self.w]\n",
    "                grad_C_b = [np.zeros_like(b) for b in self.b]\n",
    "                \n",
    "                # backprop\n",
    "                for l in range(self.L-2, -1, -1):\n",
    "                    grad_C_w[l] = np.outer(delta_l, self.a[l])\n",
    "                    grad_C_b[l] = delta_l\n",
    "                    if l > 0:\n",
    "                        delta_l = (self.w[l].T @ delta_l) * d_sigmoid(self.z[l-1])\n",
    "                \n",
    "                # muevo los parámetros en la dirección contraria al gradiente en módulo learning rate\n",
    "                self.w = [w - lr * grad_w for w, grad_w in zip(self.w, grad_C_w)]\n",
    "                self.b = [b - lr * grad_b for b, grad_b in zip(self.b, grad_C_b)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 1\n",
      "[1, 0] 1\n",
      "[1, 1] 0\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1, x2] for x1 in [0, 1] for x2 in [0, 1]]\n",
    "Y_train = [x1 ^ x2 for x1, x2 in X_train]\n",
    "\n",
    "perceptron = PerceptronMulticapa([2,3,1])\n",
    "perceptron.train(X_train, Y_train, lr=0.1, iters=10000)\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$XOR$ de $4$ entradas:\n",
    "| $x_1$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ |\n",
    "| $x_3$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "| $x_4$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $1$ | $1$ | $0$ | $1$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $0$ | $1$ | $1$ | $0$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0] 0\n",
      "[0, 0, 0, 1] 1\n",
      "[0, 0, 1, 0] 1\n",
      "[0, 0, 1, 1] 0\n",
      "[0, 1, 0, 0] 1\n",
      "[0, 1, 0, 1] 0\n",
      "[0, 1, 1, 0] 0\n",
      "[0, 1, 1, 1] 1\n",
      "[1, 0, 0, 0] 1\n",
      "[1, 0, 0, 1] 0\n",
      "[1, 0, 1, 0] 0\n",
      "[1, 0, 1, 1] 1\n",
      "[1, 1, 0, 0] 0\n",
      "[1, 1, 0, 1] 1\n",
      "[1, 1, 1, 0] 1\n",
      "[1, 1, 1, 1] 0\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1, x2, x3, x4] for x1 in [0, 1] for x2 in [0, 1] for x3 in [0, 1] for x4 in [0, 1]]\n",
    "Y_train = [x1 ^ x2 ^ x3 ^ x4 for x1, x2, x3, x4 in X_train]\n",
    "\n",
    "perceptron = PerceptronMulticapa([4,8,1])\n",
    "perceptron.train(X_train,Y_train,lr=0.01,iters=100000)\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\n",
    "    a) Implemente una red con aprendizaje Backpropagation que aprenda la siguiente función:\n",
    "    $$\n",
    "    f(x, y, z) = \\sin(x) + \\cos(y) + z\n",
    "    $$\n",
    "    donde $x, y \\in [0, 2\\pi]$ y $z \\in [-1, 1]$.  \n",
    "    Para ello construya un conjunto de datos de entrenamiento y un conjunto de evaluación. Muestre la evolución del error de entrenamiento y de evaluación en función de las épocas de entrenamiento.\n",
    "\n",
    "    b) Estudie la evolución de los errores durante el entrenamiento de una red con una capa oculta de $30$ neuronas cuando el conjunto de entrenamiento contiene $40$ muestras.  \n",
    "    ¿Qué ocurre si el minibatch tiene tamaño 40? ¿Y si tiene tamaño 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y, z):\n",
    "    return np.sin(x) + np.cos(y) + z\n",
    "\n",
    "X_train = [[x, y, z] for x, y, z in zip(np.linspace(0, 2*np.pi, 100), np.linspace(0, 2*np.pi, 100), np.linspace(-1, 1, 100))]\n",
    "Y_train = [f(x, y, z) for x, y, z in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t0.0\t-1.0\t0.51\t0.0\n",
      "0.06\t0.06\t-0.98\t0.51\t0.08\n",
      "0.13\t0.13\t-0.96\t0.51\t0.16\n",
      "0.19\t0.19\t-0.94\t0.52\t0.23\n",
      "0.25\t0.25\t-0.92\t0.52\t0.3\n",
      "0.32\t0.32\t-0.9\t0.52\t0.36\n",
      "0.38\t0.38\t-0.88\t0.52\t0.42\n",
      "0.44\t0.44\t-0.86\t0.52\t0.47\n",
      "0.51\t0.51\t-0.84\t0.52\t0.52\n",
      "0.57\t0.57\t-0.82\t0.52\t0.56\n",
      "0.63\t0.63\t-0.8\t0.51\t0.6\n",
      "0.7\t0.7\t-0.78\t0.51\t0.63\n",
      "0.76\t0.76\t-0.76\t0.51\t0.66\n",
      "0.83\t0.83\t-0.74\t0.5\t0.68\n",
      "0.89\t0.89\t-0.72\t0.5\t0.69\n",
      "0.95\t0.95\t-0.7\t0.49\t0.7\n",
      "1.02\t1.02\t-0.68\t0.48\t0.7\n",
      "1.08\t1.08\t-0.66\t0.48\t0.7\n",
      "1.14\t1.14\t-0.64\t0.46\t0.69\n",
      "1.21\t1.21\t-0.62\t0.45\t0.67\n",
      "1.27\t1.27\t-0.6\t0.44\t0.66\n",
      "1.33\t1.33\t-0.58\t0.42\t0.63\n",
      "1.4\t1.4\t-0.56\t0.4\t0.6\n",
      "1.46\t1.46\t-0.54\t0.38\t0.57\n",
      "1.52\t1.52\t-0.52\t0.35\t0.53\n",
      "1.59\t1.59\t-0.49\t0.32\t0.49\n",
      "1.65\t1.65\t-0.47\t0.29\t0.44\n",
      "1.71\t1.71\t-0.45\t0.26\t0.39\n",
      "1.78\t1.78\t-0.43\t0.23\t0.34\n",
      "1.84\t1.84\t-0.41\t0.2\t0.28\n",
      "1.9\t1.9\t-0.39\t0.17\t0.22\n",
      "1.97\t1.97\t-0.37\t0.14\t0.16\n",
      "2.03\t2.03\t-0.35\t0.12\t0.1\n",
      "2.09\t2.09\t-0.33\t0.1\t0.03\n",
      "2.16\t2.16\t-0.31\t0.08\t-0.03\n",
      "2.22\t2.22\t-0.29\t0.06\t-0.1\n",
      "2.28\t2.28\t-0.27\t0.05\t-0.17\n",
      "2.35\t2.35\t-0.25\t0.05\t-0.24\n",
      "2.41\t2.41\t-0.23\t0.04\t-0.31\n",
      "2.48\t2.48\t-0.21\t0.03\t-0.38\n",
      "2.54\t2.54\t-0.19\t0.03\t-0.45\n",
      "2.6\t2.6\t-0.17\t0.03\t-0.52\n",
      "2.67\t2.67\t-0.15\t0.02\t-0.58\n",
      "2.73\t2.73\t-0.13\t0.02\t-0.65\n",
      "2.79\t2.79\t-0.11\t0.02\t-0.71\n",
      "2.86\t2.86\t-0.09\t0.02\t-0.77\n",
      "2.92\t2.92\t-0.07\t0.02\t-0.83\n",
      "2.98\t2.98\t-0.05\t0.02\t-0.88\n",
      "3.05\t3.05\t-0.03\t0.02\t-0.93\n",
      "3.11\t3.11\t-0.01\t0.01\t-0.98\n",
      "3.17\t3.17\t0.01\t0.01\t-1.02\n",
      "3.24\t3.24\t0.03\t0.01\t-1.06\n",
      "3.3\t3.3\t0.05\t0.01\t-1.09\n",
      "3.36\t3.36\t0.07\t0.01\t-1.13\n",
      "3.43\t3.43\t0.09\t0.01\t-1.15\n",
      "3.49\t3.49\t0.11\t0.01\t-1.17\n",
      "3.55\t3.55\t0.13\t0.01\t-1.19\n",
      "3.62\t3.62\t0.15\t0.01\t-1.2\n",
      "3.68\t3.68\t0.17\t0.01\t-1.2\n",
      "3.74\t3.74\t0.19\t0.01\t-1.2\n",
      "3.81\t3.81\t0.21\t0.01\t-1.19\n",
      "3.87\t3.87\t0.23\t0.01\t-1.18\n",
      "3.93\t3.93\t0.25\t0.01\t-1.16\n",
      "4.0\t4.0\t0.27\t0.01\t-1.14\n",
      "4.06\t4.06\t0.29\t0.01\t-1.11\n",
      "4.13\t4.13\t0.31\t0.01\t-1.07\n",
      "4.19\t4.19\t0.33\t0.01\t-1.03\n",
      "4.25\t4.25\t0.35\t0.01\t-0.99\n",
      "4.32\t4.32\t0.37\t0.01\t-0.93\n",
      "4.38\t4.38\t0.39\t0.01\t-0.88\n",
      "4.44\t4.44\t0.41\t0.01\t-0.82\n",
      "4.51\t4.51\t0.43\t0.01\t-0.75\n",
      "4.57\t4.57\t0.45\t0.01\t-0.68\n",
      "4.63\t4.63\t0.47\t0.01\t-0.6\n",
      "4.7\t4.7\t0.49\t0.01\t-0.52\n",
      "4.76\t4.76\t0.52\t0.01\t-0.44\n",
      "4.82\t4.82\t0.54\t0.01\t-0.35\n",
      "4.89\t4.89\t0.56\t0.01\t-0.26\n",
      "4.95\t4.95\t0.58\t0.01\t-0.16\n",
      "5.01\t5.01\t0.6\t0.01\t-0.06\n",
      "5.08\t5.08\t0.62\t0.01\t0.04\n",
      "5.14\t5.14\t0.64\t0.01\t0.14\n",
      "5.2\t5.2\t0.66\t0.01\t0.25\n",
      "5.27\t5.27\t0.68\t0.01\t0.35\n",
      "5.33\t5.33\t0.7\t0.01\t0.46\n",
      "5.39\t5.39\t0.72\t0.01\t0.57\n",
      "5.46\t5.46\t0.74\t0.01\t0.68\n",
      "5.52\t5.52\t0.76\t0.01\t0.79\n",
      "5.59\t5.59\t0.78\t0.01\t0.9\n",
      "5.65\t5.65\t0.8\t0.01\t1.01\n",
      "5.71\t5.71\t0.82\t0.01\t1.12\n",
      "5.78\t5.78\t0.84\t0.01\t1.23\n",
      "5.84\t5.84\t0.86\t0.01\t1.33\n",
      "5.9\t5.9\t0.88\t0.01\t1.44\n",
      "5.97\t5.97\t0.9\t0.01\t1.54\n",
      "6.03\t6.03\t0.92\t0.01\t1.64\n",
      "6.09\t6.09\t0.94\t0.01\t1.73\n",
      "6.16\t6.16\t0.96\t0.01\t1.82\n",
      "6.22\t6.22\t0.98\t0.01\t1.91\n",
      "6.28\t6.28\t1.0\t0.01\t2.0\n"
     ]
    }
   ],
   "source": [
    "# voy a tener que cambiar la función costo usando el mse\n",
    "# la arquitectura no debe estar tan mal\n",
    "perceptron = PerceptronMulticapa([3,10,10,10,1])\n",
    "perceptron.train(X_train,Y_train,lr=0.01,iters=1000)\n",
    "\n",
    "for x, y, z in X_train:\n",
    "    print(str(round(x, 2))+\"\\t\"+\n",
    "          str(round(y, 2))+\"\\t\"+\n",
    "          str(round(z, 2))+\"\\t\"+\n",
    "          str(round(perceptron.predict([x, y, z])[0],2))+\"\\t\"+\n",
    "          str(round(f(x, y, z),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 100 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mperceptron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X_train,Y_train)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# plt.plot(X_train,Y_train)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 18\u001b[0m, in \u001b[0;36mPerceptronMulticapa.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma[l] \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# return 1 if self.a[-1] > 0.5 else 0\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 100 is different from 3)"
     ]
    }
   ],
   "source": [
    "Y = [perceptron.predict(x) for x in X_train]\n",
    "\n",
    "plt.plot(X_train,Y_train)\n",
    "# plt.plot(X_train,Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
