{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implemente un perceptrón simple que aprenda la función lógica $AND$ y la función lógica $OR$, de $2$ y de $4$ entradas. Muestre la evolución del error durante el entrenamiento. Para el caso de $2$ dimensiones, grafique la recta discriminadora y todos los vectores de entrada de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/perceptrón-simple1.png)\n",
    "\n",
    "$AND$ de $2$ entradas:\n",
    "| $x_1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $0$ | $0$ | $1$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(X):\n",
    "    return all(X)\n",
    "\n",
    "def OR(X):\n",
    "    return any(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSimple:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.sample(3)\n",
    "    def train(self, X, Y, alpha, iter_):\n",
    "        for _ in range(iter_):\n",
    "            for n in range(len(X)):\n",
    "                a = self.predict(X[n])\n",
    "                if a != Y[n]:\n",
    "                    self.W[0] += alpha * (Y[n] - a) * X[n][0]\n",
    "                    self.W[1] += alpha * (Y[n] - a) * X[n][1]\n",
    "                    self.W[2] += alpha * (Y[n] - a) * (-1)\n",
    "    def predict(self, x):\n",
    "        h = np.dot(np.append(x, -1), self.W)\n",
    "        return 0 if h < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 0\n",
      "[1, 0] 0\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1,x2] for x1 in [0,1] for x2 in[0,1]]\n",
    "Y_train = [AND(x) for x in X_train]\n",
    "\n",
    "perceptron = PerceptronSimple()\n",
    "perceptron.train(X_train[1:3], Y_train[1:3], 0.01, 100)\n",
    "\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$AND$ de $4$ entradas:\n",
    "\n",
    "| $x_1$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ | $0$ | $0$ | $0$ | $0$ | $1$ | $1$ | $1$ | $1$ |\n",
    "| $x_3$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $0$ | $1$ | $0$ | $0$ | $1$ | $1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "| $x_4$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $0$ | $1$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSimple:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.sample(5)\n",
    "    def train(self, X, Y, alpha, iter_):\n",
    "        for _ in range(iter_):\n",
    "            for n in range(len(X)):\n",
    "                a = self.predict(X[n])\n",
    "                if a != Y[n]:\n",
    "                    self.W[0] += alpha * (Y[n] - a) * X[n][0]\n",
    "                    self.W[1] += alpha * (Y[n] - a) * X[n][1]\n",
    "                    self.W[2] += alpha * (Y[n] - a) * X[n][2]\n",
    "                    self.W[3] += alpha * (Y[n] - a) * X[n][3]\n",
    "                    self.W[4] += alpha * (Y[n] - a) * (-1)\n",
    "    def predict(self, x):\n",
    "        h = np.dot(np.append(x, -1), self.W)\n",
    "        return 0 if h < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0] 0\n",
      "[0, 0, 0, 1] 0\n",
      "[0, 0, 1, 0] 0\n",
      "[0, 0, 1, 1] 0\n",
      "[0, 1, 0, 0] 0\n",
      "[0, 1, 0, 1] 0\n",
      "[0, 1, 1, 0] 0\n",
      "[0, 1, 1, 1] 0\n",
      "[1, 0, 0, 0] 0\n",
      "[1, 0, 0, 1] 0\n",
      "[1, 0, 1, 0] 0\n",
      "[1, 0, 1, 1] 0\n",
      "[1, 1, 0, 0] 0\n",
      "[1, 1, 0, 1] 0\n",
      "[1, 1, 1, 0] 0\n",
      "[1, 1, 1, 1] 0\n"
     ]
    }
   ],
   "source": [
    "X_train = [[x1,x2,x3,x4] for x1 in [0,1] for x2 in[0,1] for x3 in [0,1] for x4 in[0,1]]\n",
    "Y_train = [AND(x) for x in X_train]\n",
    "\n",
    "perceptron = PerceptronSimple()\n",
    "perceptron.train(X_train[7:15], Y_train[7:15], 0.01, 100)\n",
    "\n",
    "for x in X_train:\n",
    "    print(x, perceptron.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implemente un perceptrón multicapa que aprenda la función lógica $XOR$ de $2$ y de $4$ entradas (utilizando el algoritmo Backpropagation y actualizando en batch). Muestre cómo evoluciona el error durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/perceptrón-multicapa1.png)\n",
    "\n",
    "$XOR$ de $2$ entradas:\n",
    "| $x_1$ | $0$ | $0$ | $1$ | $1$ |\n",
    "|-------|-----|-----|-----|-----|\n",
    "| $x_2$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $y$   | $0$ | $1$ | $1$ | $0$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento mediante gradient-descent, consiste en calculaer el promedio del gradiente de la función costo con respecto de la matriz de pesos para cada uno de los elementos en el set de entrenamiento, para luego moverse en la dirección contraria, pues el gradiente de una función apunta en su dirección creciente.  \n",
    "El error para una muestra $X_n$ del set de entrenamiento $X$, es\n",
    "$$\n",
    "\\text{e}_X = C_X(W) = (Y_X - \\hat Y_X)^2.\n",
    "$$\n",
    "El error para todo el set de entrenamiento (para las $N$ muestras), es entonces\n",
    "$$\n",
    "\\text{e} = C(W) = \\frac{1}{N} \\sum^{N}_{k=1}(Y_k - \\hat Y_k)^2.\n",
    "$$\n",
    "El gradiente del error con respecto de la matriz de pesos es\n",
    "$$\n",
    "\\nabla e_W = \\nabla C_W =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial C}{w^{(1)}_{11}} & \\frac{\\partial C}{w^{(2)}_{11}}&\\frac{\\partial C}{w^{(3)}_{11}}\\\\\\\\\n",
    "\\frac{\\partial C}{w^{(1)}_{12}} & \\frac{\\partial C}{w^{(2)}_{12}}&\\frac{\\partial C}{w^{(3)}_{12}}\\\\\\\\\n",
    "\\frac{\\partial C}{w^{(1)}_{21}} & \\frac{\\partial C}{w^{(2)}_{21}}&\\\\\\\\\n",
    "\\frac{\\partial C}{w^{(1)}_{22}} & \\frac{\\partial C}{w^{(2)}_{22}}&\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular_parcial_e_w(bla, bla, bla, bla=1, bla=1) para generalizar?\n",
    "# recurrencia??????? probablemente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMulticapa:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.sample(10)\n",
    "    def train(self, X, Y, alpha, tol):\n",
    "        A_salida = [self.predict(x) for x in X]\n",
    "        e = np.mean((A_salida - Y)**2)\n",
    "        while e > tol:\n",
    "            for n in range(len(X)):\n",
    "                a = self.predict(X[n])\n",
    "                if a != Y[n]:\n",
    "                    self.W[0] += alpha * (Y[n] - a) * X[n][0]\n",
    "                    self.W[1] += alpha * (Y[n] - a) * X[n][1]\n",
    "                    self.W[2] += alpha * (Y[n] - a) * X[n][2]\n",
    "                    self.W[3] += alpha * (Y[n] - a) * X[n][3]\n",
    "                    self.W[4] += alpha * (Y[n] - a) * (-1)\n",
    "    def predict(self, x):\n",
    "        h = np.dot(np.append(x, -1), self.W)\n",
    "        return 0 if h < 0 else 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
